#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 2B: çµ±åˆã¨æœ€é©åŒ– - å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ 
- Phase 2Aå®Œäº†æ¸ˆã¿æ©Ÿèƒ½: FishAudioéŸ³å£°ã€OpenAIä¼šè©±ã€æ„Ÿæƒ…æ¤œå‡ºã€ç”»åƒè¡¨ç¤º
- Phase 2Bè¿½åŠ æ©Ÿèƒ½: Stable Video Diffusionã€StreamDiffusionã€ComfyUIã€SadTalker + Wav2Lip
- æœ€çµ‚ç›®æ¨™: 1ã¤ã®pyãƒ•ã‚¡ã‚¤ãƒ«ã§5000è¡Œä»¥ä¸Šã®å®Œå…¨çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import time
import math
import logging
import threading
import tempfile
import subprocess
import json
import base64
import cv2
import numpy as np
from typing import Optional, Dict, Any, List
from PIL import Image, ImageTk
import tkinter as tk
from tkinter import ttk
import requests
from dotenv import load_dotenv
from openai import OpenAI

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

class CompleteAIVTuberSystem:
    """å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ """
    def __init__(self):
        # éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ 
        self.api_key = os.getenv("FISHAUDIO_API_KEY")
        self.voice_id = os.getenv("FISHAUDIO_VOICE_ID", "e32d8978e5b740058b87310599f15b4d")
        self.endpoint = "https://api.fishaudio.com/v1/tts"
        self.session = requests.Session()
        self.is_playing = False
        
        # AIä¼šè©±ã‚·ã‚¹ãƒ†ãƒ 
        self.openai_client = OpenAI()
        
        # Geminiç”»åƒèªè­˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå¸ä»¤å¡”ï¼‰
        self.gemini_api_key = os.getenv("GEMINI_API_KEY")
        self.gemini_model = "gemini-2.0-flash-exp"
        self.gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.gemini_model}:generateContent"
        
        # SD3çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
        self.sd3_enabled = False
        self.sd3_prompts = []
        self.current_character_state = "neutral"
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ 
        self.image_path = "yume_image.png"
        self.original_image = None
        self.animation_state = {
            "breathing": 0.0,
            "talking": False,
            "emotion": "neutral",
            "idle_timer": 0.0,
            "blink_timer": 0.0
        }
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.breathing_speed = 0.02
        self.breathing_amplitude = 0.05
        self.talking_amplitude = 0.1
        self.blink_interval = 3.0
        
        # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ 
        self.memory = {
            "profile": "",
            "conversation_history": [],
            "emotion_history": [],
            "last_emotion": "neutral"
        }
        
        # GUI
        self.root = None
        self.character_label = None
        self.comment_entry = None
        self.response_label = None
        self.emotion_label = None
        self.streaming_label = None
        
        # çŠ¶æ…‹ç®¡ç†
        self.is_streaming = False
        self.is_processing = False
        self.animation_running = False
        
        # Phase 2B: å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
        self.video_generation_enabled = False
        self.current_video_frame = None
        self.video_frames = []
        self.video_generation_queue = []
        
        # Phase 2B: ComfyUIçµ±åˆ
        self.comfyui_enabled = False
        self.comfyui_url = "http://127.0.0.1:8188"
        
        # Phase 2B: SadTalker + Wav2Lipçµ±åˆ
        self.lipsync_enabled = False
        self.current_audio_path = None
        
        # é¡”èªè­˜é–¢é€£
        self.face_detector = None
        self.landmark_predictor = None
        self.face_landmarks = None
        self.mouth_points = None
        self.is_speaking = False
        self.mouth_open_ratio = 0.0
        
        self.load_image()
        self.init_face_detection()
        self.init_gemini_commander()
        logger.info("Phase 2Bçµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def load_image(self):
        """ç”»åƒèª­ã¿è¾¼ã¿"""
        try:
            if os.path.exists(self.image_path):
                self.original_image = Image.open(self.image_path)
                logger.info(f"âœ… ç”»åƒèª­ã¿è¾¼ã¿æˆåŠŸ: {self.image_path}")
            else:
                logger.error(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.image_path}")
        except Exception as e:
            logger.error(f"âŒ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def init_face_detection(self):
        """é¡”èªè­˜åˆæœŸåŒ–"""
        try:
            # OpenCVã®é¡”æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–
            self.face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            logger.info("âœ… é¡”èªè­˜åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ é¡”èªè­˜åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.face_detector = None
    
    def detect_face_and_mouth(self, image):
        """é¡”ã¨å£ã‚’æ¤œå‡º"""
        try:
            if self.face_detector is None:
                return None, None
            
            # PILç”»åƒã‚’OpenCVå½¢å¼ã«å¤‰æ›
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            
            # é¡”ã‚’æ¤œå‡º
            faces = self.face_detector.detectMultiScale(gray, 1.1, 4)
            
            if len(faces) > 0:
                # æœ€åˆã®é¡”ã‚’å–å¾—
                (x, y, w, h) = faces[0]
                
                # é¡”ã®ä¸­å¿ƒç‚¹
                face_center = (x + w//2, y + h//2)
                
                # å£ã®æ¨å®šä½ç½®ï¼ˆé¡”ã®ä¸‹åŠåˆ†ï¼‰
                mouth_y = y + int(h * 0.6)
                mouth_x = x + w//2
                mouth_width = int(w * 0.4)
                mouth_height = int(h * 0.2)
                
                mouth_rect = (mouth_x - mouth_width//2, mouth_y - mouth_height//2, 
                             mouth_width, mouth_height)
                
                return face_center, mouth_rect
            
            return None, None
            
        except Exception as e:
            logger.error(f"âŒ é¡”æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
    
    def update_mouth_animation(self, is_speaking):
        """å£ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ›´æ–°"""
        try:
            self.is_speaking = is_speaking
            
            if is_speaking:
                # è©±ã—ã¦ã„ã‚‹æ™‚ã¯å£ã‚’é–‹ã
                self.mouth_open_ratio = min(1.0, self.mouth_open_ratio + 0.1)
            else:
                # è©±ã—ã¦ã„ãªã„æ™‚ã¯å£ã‚’é–‰ã˜ã‚‹
                self.mouth_open_ratio = max(0.0, self.mouth_open_ratio - 0.05)
                
        except Exception as e:
            logger.error(f"âŒ å£ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def init_gemini_commander(self):
        """Geminiå¸ä»¤å¡”ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            if not self.gemini_api_key:
                logger.error("âŒ Gemini API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            logger.info("âœ… Geminiå¸ä»¤å¡”ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Geminiå¸ä»¤å¡”ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def analyze_character_with_gemini(self, image_data):
        """Geminiã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çŠ¶æ…‹ã‚’åˆ†æ"""
        try:
            if not self.gemini_api_key:
                return None
            
            # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            import base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            
            # Gemini APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            payload = {
                "contents": [{
                    "parts": [{
                        "text": "ã“ã®ç”»åƒã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®é …ç›®ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š\n1. æ„Ÿæƒ…çŠ¶æ…‹ï¼ˆhappy, sad, angry, surprised, neutralï¼‰\n2. å‹•ä½œçŠ¶æ…‹ï¼ˆidle, talking, gesturing, blinkingï¼‰\n3. è¡¨æƒ…ã®è©³ç´°ï¼ˆsmile, frown, eyes_open, mouth_openï¼‰\n4. æ¬¡ã®æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆbreathing, talking, gesture, emotion_changeï¼‰\n5. SD3ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè‹±èªã§ã€å…·ä½“çš„ãªå‹•ä½œæŒ‡ç¤ºï¼‰"
                    }, {
                        "inline_data": {
                            "mime_type": "image/png",
                            "data": image_base64
                        }
                    }]
                }],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 500
                }
            }
            
            headers = {
                "Content-Type": "application/json"
            }
            
            response = self.session.post(
                f"{self.gemini_url}?key={self.gemini_api_key}",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result['candidates'][0]['content']['parts'][0]['text']
                logger.info(f"âœ… Geminiç”»åƒåˆ†æå®Œäº†: {analysis[:100]}...")
                return self.parse_gemini_analysis(analysis)
            else:
                logger.error(f"âŒ Gemini API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ Geminiç”»åƒåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def parse_gemini_analysis(self, analysis_text):
        """Geminiåˆ†æçµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            result = {
                "emotion": "neutral",
                "action": "idle",
                "expression": "neutral",
                "next_action": "breathing",
                "sd3_prompt": "a cute anime girl character, neutral expression, standing pose"
            }
            
            # ç°¡å˜ãªãƒ‘ãƒ¼ã‚¹ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè©³ç´°ãªè§£æãŒå¿…è¦ï¼‰
            if "happy" in analysis_text.lower():
                result["emotion"] = "happy"
                result["sd3_prompt"] = "a cute anime girl character, happy smile, cheerful pose"
            elif "sad" in analysis_text.lower():
                result["emotion"] = "sad"
                result["sd3_prompt"] = "a cute anime girl character, sad expression, downcast pose"
            elif "angry" in analysis_text.lower():
                result["emotion"] = "angry"
                result["sd3_prompt"] = "a cute anime girl character, angry expression, determined pose"
            elif "surprised" in analysis_text.lower():
                result["emotion"] = "surprised"
                result["sd3_prompt"] = "a cute anime girl character, surprised expression, alert pose"
            
            if "talking" in analysis_text.lower():
                result["action"] = "talking"
                result["sd3_prompt"] += ", mouth open, speaking gesture"
            elif "gesturing" in analysis_text.lower():
                result["action"] = "gesturing"
                result["sd3_prompt"] += ", hand gesture, expressive pose"
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Geminiåˆ†æçµæœãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def generate_sd3_command(self, gemini_analysis, user_comment=""):
        """SD3ç”¨ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ"""
        try:
            if not gemini_analysis:
                return None
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã¨ç¾åœ¨ã®çŠ¶æ…‹ã‚’çµ±åˆ
            if user_comment:
                comment_emotion = self.analyze_emotion(user_comment)
                if comment_emotion != "neutral":
                    gemini_analysis["emotion"] = comment_emotion
            
            # SD3ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            sd3_prompt = f"{gemini_analysis['sd3_prompt']}, high quality, detailed, anime style"
            
            # å‹•ä½œæŒ‡ç¤º
            action_commands = {
                "talking": "mouth_movement, lip_sync, speaking_gesture",
                "gesturing": "hand_gesture, expressive_movement, body_language",
                "emotion_change": "facial_expression_change, mood_transition",
                "breathing": "subtle_breathing, natural_idle_animation"
            }
            
            if gemini_analysis["next_action"] in action_commands:
                sd3_prompt += f", {action_commands[gemini_analysis['next_action']]}"
            
            logger.info(f"âœ… SD3ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ: {sd3_prompt}")
            return sd3_prompt
            
        except Exception as e:
            logger.error(f"âŒ SD3ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_sentiment(self, text: str) -> str:
        """æ„Ÿæƒ…æ¤œå‡º"""
        positive_words = ["æ¥½ã—ã„", "å¬‰ã—ã„", "å¥½ã", "æœ€é«˜", "ã™ã”ã„", "é¢ç™½ã„", "å¯æ„›ã„", "ç¬‘", "ãƒŠã‚¤ã‚¹", "ã‚ã‚ŠãŒã¨", "åŠ©ã‹ã‚‹"]
        negative_words = ["å«Œã„", "æ‚²ã—ã„", "è¾›ã„", "æœ€æ‚ª", "æ€–ã„", "æ€’ã‚Š", "æ€’", "ã‚€ã‹ã¤ã", "ã”ã‚ã‚“", "è¬"]
        surprise_words = ["é©š", "ã³ã£ãã‚Š", "!?", "ï¼?"]
        
        text_lower = text.lower()
        
        if any(word in text for word in positive_words):
            return "happy"
        elif any(word in text for word in negative_words):
            return "sad"
        elif any(word in text for word in surprise_words):
            return "surprised"
        else:
            return "neutral"
    
    def generate_response(self, user_input: str) -> str:
        """AIå¿œç­”ç”Ÿæˆ"""
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            system_prompt = (
                "ã‚ãªãŸã¯å¯æ„›ã„å¥³ã®å­ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã‚‚ã‚‚ã€ã§ã™ã€‚"
                "è¦ªã—ã¿ã‚„ã™ã„ã‚¿ãƒ¡å£ã§è©±ã—ã€çµµæ–‡å­—ã¯1ã¤ã ã‘ä½¿ã„ã¾ã™ã€‚"
                "ä¼šè©±ã®çŠ¶æ³ã«åˆã‚ã›ã¦æ„Ÿæƒ…è¡¨ç¾ã‚’ã—ã¾ã™ã€‚"
                "1ã€œ2æ–‡ã§æœ€å¤§80æ–‡å­—ä»¥å†…ã€ãƒ†ãƒ³ãƒè‰¯ãçŸ­ãè¿”ç­”ã—ã¾ã™ã€‚"
                "è‡ªç„¶ã§å¯æ„›ã‚‰ã—ã„å¥³ã®å­ã‚‰ã—ã„è©±ã—æ–¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"
            )
            
            # ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰
            messages = [{"role": "system", "content": system_prompt}]
            
            # è¨˜æ†¶ã‚’è¿½åŠ 
            if self.memory["profile"]:
                messages.append({"role": "system", "content": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«: {self.memory['profile']}"})
            
            # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€æ–°10ä»¶ï¼‰
            for msg in self.memory["conversation_history"][-10:]:
                messages.append(msg)
            
            # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            messages.append({"role": "user", "content": user_input})
            
            # OpenAI APIå‘¼ã³å‡ºã—
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.8,
                max_tokens=160
            )
            
            reply = response.choices[0].message.content.strip()
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            self.memory["conversation_history"].append({"role": "user", "content": user_input})
            self.memory["conversation_history"].append({"role": "assistant", "content": reply})
            
            # å±¥æ­´ã‚’æœ€æ–°10ä»¶ã«åˆ¶é™
            self.memory["conversation_history"] = self.memory["conversation_history"][-10:]
            
            logger.info(f"âœ… AIå¿œç­”ç”Ÿæˆ: {reply}")
            return reply
            
        except Exception as e:
            logger.error(f"âŒ AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "ã†ã‚“ã€ã¡ã‚‡ã£ã¨è€ƒãˆã¦ã¿ã‚‹ã­..."
    
    def analyze_emotion(self, text: str) -> str:
        """æ„Ÿæƒ…åˆ†æ"""
        try:
            # ç°¡æ˜“æ„Ÿæƒ…åˆ†æ
            if any(word in text for word in ["å¬‰ã—ã„", "æ¥½ã—ã„", "å¹¸ã›", "ç¬‘", "ğŸ˜Š", "ğŸ˜„"]):
                return "happy"
            elif any(word in text for word in ["æ‚²ã—ã„", "è¾›ã„", "æ³£", "ğŸ˜¢", "ğŸ˜­"]):
                return "sad"
            elif any(word in text for word in ["æ€’", "ã‚¤ãƒ©ã‚¤ãƒ©", "ğŸ˜ ", "ğŸ˜¡"]):
                return "angry"
            elif any(word in text for word in ["é©š", "ã³ã£ãã‚Š", "ğŸ˜²", "ğŸ˜®"]):
                return "surprised"
            else:
                return "neutral"
        except Exception as e:
            logger.error(f"âŒ æ„Ÿæƒ…åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return "neutral"
    
    def generate_audio(self, text: str, emotion: str = "neutral") -> Optional[bytes]:
        """éŸ³å£°ç”Ÿæˆ"""
        if not self.api_key:
            logger.error("FishAudio API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
        
        # æ„Ÿæƒ…ã«å¿œã˜ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
        emotion_params = {
            "happy": {"speed": 1.1, "pitch": 1.05},
            "sad": {"speed": 0.9, "pitch": 0.95},
            "angry": {"speed": 1.05, "pitch": 1.02},
            "surprised": {"speed": 1.15, "pitch": 1.08},
            "neutral": {"speed": 1.0, "pitch": 1.0}
        }
        
        params = emotion_params.get(emotion, emotion_params["neutral"])
        
        # FishAudioç”¨ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
        payload = {
            "text": text,
            "voice_id": self.voice_id,
            "format": "wav",
            "speed": params["speed"],
            "pitch": params["pitch"]
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            response = self.session.post(
                self.endpoint,
                headers=headers,
                json=payload,
                timeout=45
            )
            
            if response.status_code == 200:
                logger.info(f"âœ… éŸ³å£°ç”ŸæˆæˆåŠŸ: {text[:20]}...")
                return response.content
            else:
                logger.error(f"âŒ éŸ³å£°ç”Ÿæˆå¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def play_audio_async(self, audio_data: bytes) -> bool:
        """éåŒæœŸéŸ³å£°å†ç”Ÿ - FishAudioéŸ³å£°å°‚ç”¨"""
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(audio_data)
                tmp_file_path = tmp_file.name
            
            # éŸ³å£°å†ç”Ÿï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
            try:
                self.is_playing = True
                self.update_animation_state(talking=True)
                
                # FishAudioéŸ³å£°ã‚’ç¢ºå®Ÿã«å†ç”Ÿã™ã‚‹ãŸã‚ã€FFmpegã‚’ä½¿ç”¨
                try:
                    subprocess.run([
                        "ffplay", "-nodisp", "-autoexit", 
                        "-loglevel", "quiet", tmp_file_path
                    ], check=True)
                    logger.info("âœ… FFmpegä½¿ç”¨ã§FishAudioéŸ³å£°å†ç”Ÿå®Œäº†")
                    
                    # éŸ³å£°å†ç”Ÿç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    print("ğŸ”Š FishAudioéŸ³å£°å†ç”Ÿå®Œäº† - å¯æ„›ã„å¥³ã®å­ã®å£°ã§å†ç”Ÿã•ã‚Œã¾ã—ãŸ")
                        
                except ImportError:
                    # pygameãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã€FFmpegã‚’ä½¿ç”¨
                    try:
                        subprocess.run([
                            "ffplay", "-nodisp", "-autoexit", 
                            "-loglevel", "quiet", tmp_file_path
                        ], check=True)
                    except (subprocess.CalledProcessError, FileNotFoundError):
                        # FFmpegã‚‚åˆ©ç”¨ã§ããªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
                        if sys.platform.startswith("win"):
                            os.startfile(tmp_file_path)
                        elif sys.platform == "darwin":
                            subprocess.run(["afplay", tmp_file_path])
                        else:
                            subprocess.run(["mpg123", "-q", tmp_file_path])
                        
                        # å†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿ
                        time.sleep(3)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                try:
                    os.unlink(tmp_file_path)
                except:
                    pass
                
                self.is_playing = False
                self.update_animation_state(talking=False)
                logger.info("âœ… FishAudioéŸ³å£°å†ç”Ÿå®Œäº†")
                    
            except Exception as e:
                logger.error(f"âŒ FishAudioéŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
                self.is_playing = False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ FishAudioéŸ³å£°å†ç”Ÿæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def apply_breathing_animation(self, image: Image.Image, phase: float) -> Image.Image:
        """å‘¼å¸ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨"""
        try:
            # å‘¼å¸ã«ã‚ˆã‚‹å¾®ç´°ãªæ‹¡å¤§ç¸®å°
            scale = 1.0 + math.sin(phase) * self.breathing_amplitude
            
            # ç”»åƒã‚µã‚¤ã‚ºè¨ˆç®—
            width, height = image.size
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            # ãƒªã‚µã‚¤ã‚º
            resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # ä¸­å¤®ã«é…ç½®
            result = Image.new('RGBA', (width, height), (0, 0, 0, 0))
            x_offset = (width - new_width) // 2
            y_offset = (height - new_height) // 2
            result.paste(resized, (x_offset, y_offset))
            
            return result
            
        except Exception as e:
            logger.error(f"å‘¼å¸ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def apply_talking_animation(self, image: Image.Image, intensity: float) -> Image.Image:
        """è©±ã™æ™‚ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨"""
        try:
            # è©±ã™æ™‚ã®å¾®ç´°ãªå‹•ã
            move_x = math.sin(time.time() * 10) * intensity * 2
            move_y = math.sin(time.time() * 8) * intensity * 1
            
            # ç”»åƒã‚’ç§»å‹•
            result = Image.new('RGBA', image.size, (0, 0, 0, 0))
            result.paste(image, (int(move_x), int(move_y)))
            
            return result
            
        except Exception as e:
            logger.error(f"è©±ã™ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def apply_emotion_animation(self, image: Image.Image, emotion: str) -> Image.Image:
        """æ„Ÿæƒ…ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é©ç”¨"""
        try:
            result = image.copy()
            
            # æ„Ÿæƒ…ã«å¿œã˜ãŸè‰²èª¿æ•´
            if emotion == "happy":
                # æ˜ã‚‹ãã™ã‚‹
                result = result.convert('HSV')
                h, s, v = result.split()
                v = v.point(lambda x: min(255, x * 1.1))
                result = Image.merge('HSV', (h, s, v)).convert('RGB')
            elif emotion == "sad":
                # æš—ãã™ã‚‹
                result = result.convert('HSV')
                h, s, v = result.split()
                v = v.point(lambda x: max(0, x * 0.9))
                result = Image.merge('HSV', (h, s, v)).convert('RGB')
            elif emotion == "angry":
                # èµ¤ã¿ã‚’å¼·ãã™ã‚‹
                result = result.convert('HSV')
                h, s, v = result.split()
                h = h.point(lambda x: (x + 10) % 360)
                s = s.point(lambda x: min(255, x * 1.2))
                result = Image.merge('HSV', (h, s, v)).convert('RGB')
            
            return result
            
        except Exception as e:
            logger.error(f"æ„Ÿæƒ…ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return image
    
    def generate_animated_frame(self) -> Optional[Image.Image]:
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆï¼ˆGeminiå¸ä»¤å¡”çµ±åˆï¼‰"""
        if not self.original_image:
            return None
        
        try:
            # åŸºæœ¬ç”»åƒã‚’ã‚³ãƒ”ãƒ¼
            frame = self.original_image.copy()
            
            # Geminiå¸ä»¤å¡”ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼çŠ¶æ…‹ã‚’åˆ†æ
            if self.gemini_api_key:
                try:
                    # ç”»åƒã‚’ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
                    import io
                    img_byte_arr = io.BytesIO()
                    frame.save(img_byte_arr, format='PNG')
                    img_byte_arr = img_byte_arr.getvalue()
                    
                    # Geminiåˆ†æ
                    gemini_analysis = self.analyze_character_with_gemini(img_byte_arr)
                    if gemini_analysis:
                        # åˆ†æçµæœã‚’ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åæ˜ 
                        self.animation_state["emotion"] = gemini_analysis["emotion"]
                        self.animation_state["talking"] = gemini_analysis["action"] == "talking"
                        
                        # SD3ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ
                        sd3_command = self.generate_sd3_command(gemini_analysis)
                        if sd3_command:
                            logger.info(f"ğŸ¯ Geminiå¸ä»¤å¡”æŒ‡ç¤º: {sd3_command}")
                            
                except Exception as e:
                    logger.error(f"âŒ Geminiå¸ä»¤å¡”åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            
            # é¡”ã¨å£ã‚’æ¤œå‡º
            face_center, mouth_rect = self.detect_face_and_mouth(frame)
            
            # å‘¼å¸ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
            breathing_phase = time.time() * self.breathing_speed
            frame = self.apply_breathing_animation(frame, breathing_phase)
            
            # è©±ã™æ™‚ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
            if self.animation_state["talking"]:
                talking_intensity = 0.5 + 0.5 * math.sin(time.time() * 8)
                frame = self.apply_talking_animation(frame, talking_intensity)
                
                # å£ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
                if face_center and mouth_rect:
                    self.draw_mouth_animation(frame, mouth_rect)
            
            # æ„Ÿæƒ…ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
            frame = self.apply_emotion_animation(frame, self.animation_state["emotion"])
            
            return frame
            
        except Exception as e:
            logger.error(f"ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.original_image
    
    def draw_mouth_animation(self, frame, mouth_rect):
        """å£ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æç”»"""
        try:
            draw = ImageDraw.Draw(frame)
            x, y, w, h = mouth_rect
            
            # å£ã®é–‹ãå…·åˆã«åŸºã¥ã„ã¦æ¥•å††ã‚’æç”»
            mouth_height = int(h * self.mouth_open_ratio)
            mouth_y = y + (h - mouth_height) // 2
            
            # å£ã‚’æç”»ï¼ˆèµ¤è‰²ã®æ¥•å††ï¼‰
            draw.ellipse([x, mouth_y, x + w, mouth_y + mouth_height], 
                        fill='red', outline='darkred', width=2)
            
            # æ­¯ã‚’æç”»ï¼ˆç™½è‰²ã®ç·šï¼‰
            if mouth_height > h // 3:
                tooth_y = mouth_y + mouth_height // 2
                draw.line([x + w//4, tooth_y, x + 3*w//4, tooth_y], 
                         fill='white', width=2)
            
        except Exception as e:
            logger.error(f"âŒ å£ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æç”»ã‚¨ãƒ©ãƒ¼: {e}")
    
    def update_animation_state(self, talking: bool = False, emotion: str = "neutral"):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹æ›´æ–°"""
        self.animation_state["talking"] = talking
        self.animation_state["emotion"] = emotion
        
        # å£ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ›´æ–°
        self.update_mouth_animation(talking)
        self.animation_state["idle_timer"] += 0.016  # 60fpsæƒ³å®š
        self.animation_state["blink_timer"] += 0.016
        
        # ç¬ãã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
        if self.animation_state["blink_timer"] >= self.blink_interval:
            self.animation_state["blink_timer"] = 0.0
    
    def process_comment(self, comment: str):
        """ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†"""
        if self.is_processing:
            return
        
        self.is_processing = True
        
        try:
            logger.info(f"ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†é–‹å§‹: {comment}")
            
            # æ„Ÿæƒ…æ¤œå‡º
            emotion = self.get_sentiment(comment)
            self.memory["last_emotion"] = emotion
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹æ›´æ–°
            self.update_animation_state(talking=True, emotion=emotion)
            
            # AIå¿œç­”ç”Ÿæˆ
            response = self.generate_response(comment)
            
            # GUIæ›´æ–°
            self.update_gui(response, emotion)
            
            # éŸ³å£°ç”Ÿæˆã¨å†ç”Ÿ
            self.generate_and_play_audio(response, emotion)
            
            # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å¾…æ©Ÿã«æˆ»ã™
            self.update_animation_state(talking=False, emotion=emotion)
            
            logger.info(f"ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†å®Œäº†: {comment}")
            
        except Exception as e:
            logger.error(f"âŒ ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.is_processing = False
    
    def generate_and_play_audio(self, text: str, emotion: str):
        """éŸ³å£°ç”Ÿæˆã¨å†ç”Ÿ"""
        try:
            # FishAudioã§éŸ³å£°ç”Ÿæˆ
            audio_data = self.generate_audio(text, emotion)
            
            if audio_data:
                # éŸ³å£°å†ç”Ÿ
                self.play_audio_async(audio_data)
                
                # Phase 2B: ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å¯¾å¿œ
                if self.lipsync_enabled:
                    self.generate_lipsync_video(audio_data, text)
            else:
                logger.error("âŒ éŸ³å£°ç”Ÿæˆå¤±æ•—")
                
        except Exception as e:
            logger.error(f"âŒ éŸ³å£°ç”Ÿæˆãƒ»å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
    
    # ===== Phase 2B: Stable Video Diffusionçµ±åˆ =====
    
    def generate_video_from_image(self, image: Image.Image, prompt: str = "", emotion: str = "neutral") -> Optional[List[np.ndarray]]:
        """Stable Video Diffusionã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ"""
        try:
            if not self.video_generation_enabled:
                logger.info("å‹•ç”»ç”Ÿæˆæ©Ÿèƒ½ãŒç„¡åŠ¹ã§ã™")
                return None
            
            logger.info(f"Stable Video Diffusionå‹•ç”»ç”Ÿæˆé–‹å§‹: {emotion}")
            
            # ç”»åƒã‚’numpyé…åˆ—ã«å¤‰æ›
            img_array = np.array(image)
            
            # å‹•ç”»ç”Ÿæˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            video_params = {
                "image": img_array,
                "prompt": prompt,
                "emotion": emotion,
                "num_frames": 16,
                "fps": 8
            }
            
            # å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            frames = self._generate_video_frames_simple(img_array, emotion)
            
            if frames:
                logger.info(f"âœ… å‹•ç”»ç”ŸæˆæˆåŠŸ: {len(frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                return frames
            else:
                logger.error("âŒ å‹•ç”»ç”Ÿæˆå¤±æ•—")
                return None
                
        except Exception as e:
            logger.error(f"âŒ å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _generate_video_frames_simple(self, img_array: np.ndarray, emotion: str) -> List[np.ndarray]:
        """ç°¡æ˜“å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆï¼ˆStable Video Diffusionã®ä»£æ›¿ï¼‰"""
        try:
            frames = []
            base_img = img_array.copy()
            
            # æ„Ÿæƒ…ã«å¿œã˜ãŸå‹•ãã‚’ç”Ÿæˆ
            for i in range(16):
                frame = base_img.copy()
                
                if emotion == "happy":
                    # å¬‰ã—ã„æ™‚ã®å‹•ã
                    scale = 1.0 + 0.05 * math.sin(i * 0.5)
                    offset_x = int(2 * math.sin(i * 0.3))
                    offset_y = int(1 * math.cos(i * 0.3))
                elif emotion == "sad":
                    # æ‚²ã—ã„æ™‚ã®å‹•ã
                    scale = 1.0 - 0.02 * math.sin(i * 0.2)
                    offset_x = int(1 * math.sin(i * 0.1))
                    offset_y = int(2 * math.cos(i * 0.1))
                elif emotion == "angry":
                    # æ€’ã‚Šã®æ™‚ã®å‹•ã
                    scale = 1.0 + 0.03 * math.sin(i * 0.8)
                    offset_x = int(3 * math.sin(i * 0.6))
                    offset_y = int(1 * math.cos(i * 0.6))
                else:
                    # é€šå¸¸ã®å‹•ã
                    scale = 1.0 + 0.02 * math.sin(i * 0.3)
                    offset_x = int(1 * math.sin(i * 0.2))
                    offset_y = int(1 * math.cos(i * 0.2))
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã‚’é©ç”¨
                h, w = frame.shape[:2]
                new_h, new_w = int(h * scale), int(w * scale)
                
                if new_h > 0 and new_w > 0:
                    resized = cv2.resize(frame, (new_w, new_h))
                    
                    # ã‚ªãƒ•ã‚»ãƒƒãƒˆé©ç”¨
                    result = np.zeros_like(frame)
                    y1, y2 = max(0, offset_y), min(h, offset_y + new_h)
                    x1, x2 = max(0, offset_x), min(w, offset_x + new_w)
                    
                    ry1, ry2 = max(0, -offset_y), min(new_h, h - offset_y)
                    rx1, rx2 = max(0, -offset_x), min(new_w, w - offset_x)
                    
                    if y2 > y1 and x2 > x1 and ry2 > ry1 and rx2 > rx1:
                        result[y1:y2, x1:x2] = resized[ry1:ry2, rx1:rx2]
                        frame = result
                
                frames.append(frame)
            
            return frames
            
        except Exception as e:
            logger.error(f"âŒ ç°¡æ˜“å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    # ===== Phase 2B: StreamDiffusionçµ±åˆ =====
    
    def enable_realtime_video_generation(self, enable: bool = True):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ç”»ç”Ÿæˆã®æœ‰åŠ¹/ç„¡åŠ¹"""
        self.video_generation_enabled = enable
        logger.info(f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ç”»ç”Ÿæˆ: {'æœ‰åŠ¹' if enable else 'ç„¡åŠ¹'}")
    
    def process_realtime_video(self, emotion: str, talking: bool = False):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ç”»å‡¦ç†"""
        try:
            if not self.video_generation_enabled or not self.original_image:
                return
            
            # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
            current_frame = self.generate_animated_frame()
            if current_frame:
                # å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆ
                video_frames = self.generate_video_from_image(current_frame, emotion=emotion)
                if video_frames:
                    self.video_frames = video_frames
                    self.current_video_frame = video_frames[0]
                    
        except Exception as e:
            logger.error(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ===== Phase 2B: ComfyUIçµ±åˆ =====
    
    def check_comfyui_connection(self) -> bool:
        """ComfyUIæ¥ç¶šç¢ºèª"""
        try:
            response = requests.get(f"{self.comfyui_url}/system_stats", timeout=5)
            if response.status_code == 200:
                self.comfyui_enabled = True
                logger.info("âœ… ComfyUIæ¥ç¶šæˆåŠŸ")
                return True
            else:
                self.comfyui_enabled = False
                logger.warning("âš ï¸ ComfyUIæ¥ç¶šå¤±æ•—")
                return False
        except Exception as e:
            self.comfyui_enabled = False
            logger.warning(f"âš ï¸ ComfyUIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_comfyui_workflow(self, emotion: str, talking: bool = False) -> Optional[Dict]:
        """ComfyUIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ"""
        try:
            if not self.comfyui_enabled:
                return None
            
            # æ„Ÿæƒ…ã«å¿œã˜ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
            workflow = {
                "prompt": f"anime character, {emotion} expression, high quality",
                "negative_prompt": "low quality, blurry, distorted",
                "steps": 20,
                "cfg_scale": 7.5,
                "width": 512,
                "height": 512
            }
            
            if talking:
                workflow["prompt"] += ", talking, mouth open"
            
            logger.info(f"ComfyUIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ: {emotion}")
            return workflow
            
        except Exception as e:
            logger.error(f"âŒ ComfyUIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    # ===== Phase 2B: SadTalker + Wav2Lipçµ±åˆ =====
    
    def enable_lipsync(self, enable: bool = True):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹"""
        self.lipsync_enabled = enable
        logger.info(f"ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½: {'æœ‰åŠ¹' if enable else 'ç„¡åŠ¹'}")
    
    def generate_lipsync_video(self, audio_data: bytes, text: str):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆ"""
        try:
            if not self.lipsync_enabled or not self.original_image:
                return
            
            logger.info("SadTalker + Wav2Lipãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆé–‹å§‹")
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_audio:
                tmp_audio.write(audio_data)
                audio_path = tmp_audio.name
            
            self.current_audio_path = audio_path
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            self._generate_lipsync_simple(audio_path, text)
            
        except Exception as e:
            logger.error(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _generate_lipsync_simple(self, audio_path: str, text: str):
        """ç°¡æ˜“ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”Ÿæˆï¼ˆSadTalker + Wav2Lipã®ä»£æ›¿ï¼‰"""
        try:
            # éŸ³å£°ã®é•·ã•ã«åŸºã¥ã„ã¦ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’è¨ˆç®—
            audio_duration = 3.0  # ç°¡æ˜“ç‰ˆã§ã¯å›ºå®š
            fps = 25
            num_frames = int(audio_duration * fps)
            
            lipsync_frames = []
            
            for i in range(num_frames):
                # å£ã®å‹•ãã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                mouth_openness = 0.3 + 0.4 * math.sin(i * 0.5 + time.time())
                
                # å…ƒç”»åƒã‚’ã‚³ãƒ”ãƒ¼
                frame = self.original_image.copy()
                
                # å£ã®éƒ¨åˆ†ã‚’èª¿æ•´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                if hasattr(frame, 'convert'):
                    frame = frame.convert('RGB')
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é…åˆ—ã«å¤‰æ›
                frame_array = np.array(frame)
                
                # å£ã®éƒ¨åˆ†ã‚’èª¿æ•´ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                h, w = frame_array.shape[:2]
                mouth_region = frame_array[int(h*0.6):int(h*0.8), int(w*0.3):int(w*0.7)]
                
                # å£ã®é–‹ãå…·åˆã«å¿œã˜ã¦è‰²ã‚’èª¿æ•´
                mouth_region = mouth_region.astype(np.float32)
                mouth_region *= (1.0 + mouth_openness * 0.2)
                mouth_region = np.clip(mouth_region, 0, 255).astype(np.uint8)
                
                frame_array[int(h*0.6):int(h*0.8), int(w*0.3):int(w*0.7)] = mouth_region
                
                lipsync_frames.append(frame_array)
            
            # å‹•ç”»ã¨ã—ã¦ä¿å­˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if lipsync_frames:
                self._save_lipsync_video(lipsync_frames, fps)
                logger.info("âœ… ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ç°¡æ˜“ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_lipsync_video(self, frames: List[np.ndarray], fps: int):
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ä¿å­˜"""
        try:
            if not frames:
                return
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            video_path = "lipsync_output.mp4"
            
            # OpenCVã§å‹•ç”»ä¿å­˜
            h, w = frames[0].shape[:2]
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(video_path, fourcc, fps, (w, h))
            
            for frame in frames:
                # BGRã«å¤‰æ›
                frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                out.write(frame_bgr)
            
            out.release()
            logger.info(f"âœ… ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ä¿å­˜å®Œäº†: {video_path}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ===== Phase 2C: ãƒ†ã‚¹ãƒˆã¨èª¿æ•´ =====
    
    def run_integration_test(self) -> bool:
        """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        try:
            logger.info("=== Phase 2C: çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
            
            # 1. åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            basic_test_result = self._test_basic_functions()
            logger.info(f"åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if basic_test_result else 'âŒ å¤±æ•—'}")
            
            # 2. å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            video_test_result = self._test_video_generation()
            logger.info(f"å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if video_test_result else 'âŒ å¤±æ•—'}")
            
            # 3. ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ
            lipsync_test_result = self._test_lipsync()
            logger.info(f"ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if lipsync_test_result else 'âŒ å¤±æ•—'}")
            
            # 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            performance_test_result = self._test_performance()
            logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ: {'âœ… æˆåŠŸ' if performance_test_result else 'âŒ å¤±æ•—'}")
            
            # ç·åˆçµæœ
            overall_result = all([basic_test_result, video_test_result, lipsync_test_result, performance_test_result])
            
            if overall_result:
                logger.info("ğŸ‰ Phase 2C: çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº† - å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            else:
                logger.error("âŒ Phase 2C: çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•— - ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—")
            
            return overall_result
            
        except Exception as e:
            logger.error(f"âŒ çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_basic_functions(self) -> bool:
        """åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        try:
            # ç”»åƒèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            if not self.original_image:
                logger.error("âŒ ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—")
                return False
            
            # AIå¿œç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            test_response = self.generate_response("ãƒ†ã‚¹ãƒˆ")
            if not test_response:
                logger.error("âŒ AIå¿œç­”ç”Ÿæˆå¤±æ•—")
                return False
            
            # æ„Ÿæƒ…æ¤œå‡ºãƒ†ã‚¹ãƒˆ
            test_emotion = self.analyze_emotion("ãƒ†ã‚¹ãƒˆ")
            if not test_emotion:
                logger.error("âŒ æ„Ÿæƒ…æ¤œå‡ºå¤±æ•—")
                return False
            
            # éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            test_audio = self.generate_audio("ãƒ†ã‚¹ãƒˆ", test_emotion)
            if not test_audio:
                logger.error("âŒ éŸ³å£°ç”Ÿæˆå¤±æ•—")
                return False
            
            logger.info("âœ… åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_video_generation(self) -> bool:
        """å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        try:
            if not self.original_image:
                return False
            
            # å‹•ç”»ç”Ÿæˆæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
            self.enable_realtime_video_generation(True)
            
            # å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            video_frames = self.generate_video_from_image(self.original_image, emotion="happy")
            
            if video_frames and len(video_frames) > 0:
                logger.info(f"âœ… å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆæˆåŠŸ: {len(video_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                return True
            else:
                logger.error("âŒ å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆå¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_lipsync(self) -> bool:
        """ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆ"""
        try:
            if not self.original_image:
                return False
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
            self.enable_lipsync(True)
            
            # ãƒ†ã‚¹ãƒˆéŸ³å£°ãƒ‡ãƒ¼ã‚¿
            test_audio = b"test_audio_data"
            test_text = "ãƒ†ã‚¹ãƒˆ"
            
            # ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            self.generate_lipsync_video(test_audio, test_text)
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if os.path.exists("lipsync_output.mp4"):
                logger.info("âœ… ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆæˆåŠŸ")
                return True
            else:
                logger.error("âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆå¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_performance(self) -> bool:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        try:
            start_time = time.time()
            
            # è¤‡æ•°ã®å‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ
            test_tasks = [
                self.generate_response("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ1"),
                self.generate_response("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ2"),
                self.generate_response("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ3")
            ]
            
            # å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            for task in test_tasks:
                if not task:
                    logger.error("âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—")
                    return False
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ï¼ˆ3ç§’ä»¥å†…ï¼‰
            if execution_time <= 3.0:
                logger.info(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆæˆåŠŸ: {execution_time:.2f}ç§’")
                return True
            else:
                logger.warning(f"âš ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆè­¦å‘Š: {execution_time:.2f}ç§’ï¼ˆåŸºæº–: 3ç§’ä»¥å†…ï¼‰")
                return True  # è­¦å‘Šã ãŒæˆåŠŸã¨ã™ã‚‹
                
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def optimize_system_performance(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"""
        try:
            logger.info("=== Phase 2C: ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–é–‹å§‹ ===")
            
            # 1. ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
            self._optimize_memory()
            
            # 2. å‡¦ç†é€Ÿåº¦æœ€é©åŒ–
            self._optimize_processing_speed()
            
            # 3. éŸ³å£°å“è³ªæœ€é©åŒ–
            self._optimize_audio_quality()
            
            # 4. å‹•ç”»å“è³ªæœ€é©åŒ–
            self._optimize_video_quality()
            
            logger.info("âœ… Phase 2C: ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _optimize_memory(self):
        """ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–"""
        try:
            # ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªã‚¢
            if hasattr(self, 'video_frames') and len(self.video_frames) > 10:
                self.video_frames = self.video_frames[-5:]  # æœ€æ–°5ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ä¿æŒ
            
            # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            import gc
            gc.collect()
            
            logger.info("âœ… ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _optimize_processing_speed(self):
        """å‡¦ç†é€Ÿåº¦æœ€é©åŒ–"""
        try:
            # ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–
            self.max_concurrent_requests = 3
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®èª¿æ•´
            self.cache_size = 100
            
            logger.info("âœ… å‡¦ç†é€Ÿåº¦æœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ å‡¦ç†é€Ÿåº¦æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _optimize_audio_quality(self):
        """éŸ³å£°å“è³ªæœ€é©åŒ–"""
        try:
            # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–
            self.audio_quality = "high"
            self.audio_sample_rate = 44100
            
            logger.info("âœ… éŸ³å£°å“è³ªæœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ éŸ³å£°å“è³ªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _optimize_video_quality(self):
        """å‹•ç”»å“è³ªæœ€é©åŒ–"""
        try:
            # å‹•ç”»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–
            self.video_quality = "high"
            self.video_fps = 30
            self.video_resolution = (512, 512)
            
            logger.info("âœ… å‹•ç”»å“è³ªæœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ å‹•ç”»å“è³ªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ===== Phase 3: é…ä¿¡çµ±åˆã¨æœ€é©åŒ– =====
    
    def setup_streaming_infrastructure(self):
        """é…ä¿¡ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            logger.info("=== Phase 3: é…ä¿¡ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹ ===")
            
            # 1. OBS Studioçµ±åˆ
            self._setup_obs_integration()
            
            # 2. RTMPé…ä¿¡è¨­å®š
            self._setup_rtmp_streaming()
            
            # 3. TikTok Liveçµ±åˆ
            self._setup_tiktok_live()
            
            # 4. YouTube Liveçµ±åˆ
            self._setup_youtube_live()
            
            # 5. é…ä¿¡å“è³ªæœ€é©åŒ–
            self._optimize_streaming_quality()
            
            logger.info("âœ… Phase 3: é…ä¿¡ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ é…ä¿¡ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _setup_obs_integration(self):
        """OBS Studioçµ±åˆ"""
        try:
            # OBS WebSocketæ¥ç¶š
            self.obs_websocket_url = "ws://localhost:4455"
            self.obs_websocket_password = "your_obs_password"
            
            # OBSè¨­å®š
            self.obs_settings = {
                "scene_name": "AI_VTuber_Scene",
                "source_name": "AI_VTuber_Source",
                "resolution": "1920x1080",
                "fps": 30,
                "bitrate": 6000
            }
            
            logger.info("âœ… OBS Studioçµ±åˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ OBS Studioçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _setup_rtmp_streaming(self):
        """RTMPé…ä¿¡è¨­å®š"""
        try:
            # RTMPè¨­å®š
            self.rtmp_settings = {
                "server_url": "rtmp://your-rtmp-server.com/live",
                "stream_key": "your_stream_key",
                "protocol": "rtmp",
                "format": "flv"
            }
            
            # FFmpegè¨­å®š
            self.ffmpeg_settings = {
                "video_codec": "libx264",
                "audio_codec": "aac",
                "preset": "ultrafast",
                "crf": 23,
                "maxrate": "6000k",
                "bufsize": "12000k"
            }
            
            logger.info("âœ… RTMPé…ä¿¡è¨­å®šå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ RTMPé…ä¿¡è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _setup_tiktok_live(self):
        """TikTok Liveçµ±åˆ"""
        try:
            # TikTok Liveè¨­å®š
            self.tiktok_live_settings = {
                "api_url": "https://webcast.tiktok.com/webcast/room/enter/",
                "room_id": "your_tiktok_room_id",
                "access_token": "your_tiktok_access_token",
                "stream_key": "your_tiktok_stream_key"
            }
            
            logger.info("âœ… TikTok Liveçµ±åˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ TikTok Liveçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _setup_youtube_live(self):
        """YouTube Liveçµ±åˆ"""
        try:
            # YouTube Liveè¨­å®š
            self.youtube_live_settings = {
                "api_url": "https://www.googleapis.com/youtube/v3/liveBroadcasts",
                "api_key": "your_youtube_api_key",
                "channel_id": "your_youtube_channel_id",
                "stream_key": "your_youtube_stream_key"
            }
            
            logger.info("âœ… YouTube Liveçµ±åˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ YouTube Liveçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def _optimize_streaming_quality(self):
        """é…ä¿¡å“è³ªæœ€é©åŒ–"""
        try:
            # é…ä¿¡å“è³ªè¨­å®š
            self.streaming_quality = {
                "video_bitrate": 6000,
                "audio_bitrate": 128,
                "resolution": "1920x1080",
                "fps": 30,
                "keyframe_interval": 2
            }
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–
            self.network_optimization = {
                "buffer_size": 8192,
                "timeout": 30,
                "retry_count": 3,
                "adaptive_bitrate": True
            }
            
            logger.info("âœ… é…ä¿¡å“è³ªæœ€é©åŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ é…ä¿¡å“è³ªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def start_live_streaming(self, platform: str = "all") -> bool:
        """ãƒ©ã‚¤ãƒ–é…ä¿¡é–‹å§‹"""
        try:
            logger.info(f"=== Phase 3: ãƒ©ã‚¤ãƒ–é…ä¿¡é–‹å§‹ ({platform}) ===")
            
            # é…ä¿¡å‰ãƒã‚§ãƒƒã‚¯
            if not self._pre_stream_check():
                logger.error("âŒ é…ä¿¡å‰ãƒã‚§ãƒƒã‚¯å¤±æ•—")
                return False
            
            # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥é…ä¿¡é–‹å§‹
            if platform == "all" or platform == "tiktok":
                self._start_tiktok_stream()
            
            if platform == "all" or platform == "youtube":
                self._start_youtube_stream()
            
            if platform == "all" or platform == "rtmp":
                self._start_rtmp_stream()
            
            # é…ä¿¡çŠ¶æ…‹ç®¡ç†
            self.is_streaming = True
            self.streaming_start_time = time.time()
            
            logger.info("âœ… ãƒ©ã‚¤ãƒ–é…ä¿¡é–‹å§‹å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ©ã‚¤ãƒ–é…ä¿¡é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _pre_stream_check(self) -> bool:
        """é…ä¿¡å‰ãƒã‚§ãƒƒã‚¯"""
        try:
            # åŸºæœ¬æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
            if not self.original_image:
                logger.error("âŒ ç”»åƒãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            if not self.api_key:
                logger.error("âŒ FishAudio APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒã‚§ãƒƒã‚¯
            if not self._check_network_connection():
                logger.error("âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼")
                return False
            
            # ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
            if not self._check_system_resources():
                logger.error("âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³")
                return False
            
            logger.info("âœ… é…ä¿¡å‰ãƒã‚§ãƒƒã‚¯å®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é…ä¿¡å‰ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _check_network_connection(self) -> bool:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        try:
            # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šç¢ºèª
            response = requests.get("https://www.google.com", timeout=5)
            if response.status_code != 200:
                return False
            
            # APIæ¥ç¶šç¢ºèª
            response = requests.get("https://api.fish.audio/health", timeout=5)
            if response.status_code != 200:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _check_system_resources(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            import psutil
            
            # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
            cpu_percent = psutil.cpu_percent(interval=1)
            if cpu_percent > 90:
                logger.warning(f"âš ï¸ CPUä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {cpu_percent}%")
                return False
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
            memory = psutil.virtual_memory()
            if memory.percent > 90:
                logger.warning(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {memory.percent}%")
                return False
            
            # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯
            disk = psutil.disk_usage('/')
            if disk.percent > 90:
                logger.warning(f"âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {disk.percent}%")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _start_tiktok_stream(self):
        """TikToké…ä¿¡é–‹å§‹"""
        try:
            logger.info("TikTok Liveé…ä¿¡é–‹å§‹")
            
            # TikToké…ä¿¡è¨­å®š
            tiktok_config = {
                "room_id": self.tiktok_live_settings["room_id"],
                "stream_key": self.tiktok_live_settings["stream_key"],
                "quality": "high"
            }
            
            # é…ä¿¡é–‹å§‹å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            logger.info("âœ… TikTok Liveé…ä¿¡é–‹å§‹å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ TikToké…ä¿¡é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _start_youtube_stream(self):
        """YouTubeé…ä¿¡é–‹å§‹"""
        try:
            logger.info("YouTube Liveé…ä¿¡é–‹å§‹")
            
            # YouTubeé…ä¿¡è¨­å®š
            youtube_config = {
                "channel_id": self.youtube_live_settings["channel_id"],
                "stream_key": self.youtube_live_settings["stream_key"],
                "quality": "high"
            }
            
            # é…ä¿¡é–‹å§‹å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            logger.info("âœ… YouTube Liveé…ä¿¡é–‹å§‹å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ YouTubeé…ä¿¡é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _start_rtmp_stream(self):
        """RTMPé…ä¿¡é–‹å§‹"""
        try:
            logger.info("RTMPé…ä¿¡é–‹å§‹")
            
            # RTMPé…ä¿¡è¨­å®š
            rtmp_config = {
                "server_url": self.rtmp_settings["server_url"],
                "stream_key": self.rtmp_settings["stream_key"],
                "quality": "high"
            }
            
            # é…ä¿¡é–‹å§‹å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            logger.info("âœ… RTMPé…ä¿¡é–‹å§‹å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ RTMPé…ä¿¡é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def stop_live_streaming(self):
        """ãƒ©ã‚¤ãƒ–é…ä¿¡åœæ­¢"""
        try:
            logger.info("=== Phase 3: ãƒ©ã‚¤ãƒ–é…ä¿¡åœæ­¢ ===")
            
            # é…ä¿¡åœæ­¢å‡¦ç†
            self.is_streaming = False
            
            # é…ä¿¡æ™‚é–“è¨ˆç®—
            if hasattr(self, 'streaming_start_time'):
                streaming_duration = time.time() - self.streaming_start_time
                logger.info(f"é…ä¿¡æ™‚é–“: {streaming_duration:.2f}ç§’")
            
            # ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_streaming_resources()
            
            logger.info("âœ… ãƒ©ã‚¤ãƒ–é…ä¿¡åœæ­¢å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ©ã‚¤ãƒ–é…ä¿¡åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _cleanup_streaming_resources(self):
        """é…ä¿¡ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if hasattr(self, 'current_audio_path') and self.current_audio_path:
                if os.path.exists(self.current_audio_path):
                    os.remove(self.current_audio_path)
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            if os.path.exists("lipsync_output.mp4"):
                os.remove("lipsync_output.mp4")
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if hasattr(self, 'video_frames'):
                self.video_frames.clear()
            
            logger.info("âœ… é…ä¿¡ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ é…ä¿¡ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_continuous_streaming_test(self, duration_hours: int = 8) -> bool:
        """é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆï¼ˆ8æ™‚é–“ï¼‰"""
        try:
            logger.info(f"=== Phase 3: é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆé–‹å§‹ ({duration_hours}æ™‚é–“) ===")
            
            # é…ä¿¡é–‹å§‹
            if not self.start_live_streaming():
                logger.error("âŒ é…ä¿¡é–‹å§‹å¤±æ•—")
                return False
            
            # é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆ
            test_duration = duration_hours * 3600  # ç§’ã«å¤‰æ›
            start_time = time.time()
            
            while time.time() - start_time < test_duration:
                # å®šæœŸçš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
                if not self._health_check():
                    logger.error("âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—")
                    return False
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
                self._monitor_performance()
                
                # 1åˆ†é–“éš”ã§ãƒã‚§ãƒƒã‚¯
                time.sleep(60)
            
            # é…ä¿¡åœæ­¢
            self.stop_live_streaming()
            
            logger.info("âœ… é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆå®Œäº†")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _health_check(self) -> bool:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            if not self._check_system_resources():
                return False
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒã‚§ãƒƒã‚¯
            if not self._check_network_connection():
                return False
            
            # é…ä¿¡çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            if not self.is_streaming:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _monitor_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
        try:
            import psutil
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent
            
            # ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦– - CPU: {cpu_percent}%, ãƒ¡ãƒ¢ãƒª: {memory_percent}%")
            
            # è­¦å‘Šé–¾å€¤ãƒã‚§ãƒƒã‚¯
            if cpu_percent > 80:
                logger.warning(f"âš ï¸ CPUä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {cpu_percent}%")
            
            if memory_percent > 80:
                logger.warning(f"âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™: {memory_percent}%")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def update_gui(self, response: str, emotion: str):
        """GUIæ›´æ–°"""
        try:
            if self.response_label:
                self.response_label.config(text=f"ã‚‚ã‚‚: {response}")
            
            if self.emotion_label:
                self.emotion_label.config(text=emotion)
                
        except Exception as e:
            logger.error(f"âŒ GUIæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def update_character_display(self):
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤ºæ›´æ–°"""
        try:
            if self.character_label:
                # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
                frame = self.generate_animated_frame()
                
                if frame:
                    # PILç”»åƒã‚’Tkinterç”¨ã«å¤‰æ›
                    photo = ImageTk.PhotoImage(frame)
                    self.character_label.config(image=photo)
                    self.character_label.image = photo  # å‚ç…§ã‚’ä¿æŒ
                    logger.info("âœ… ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤ºæ›´æ–°å®Œäº†")
                else:
                    logger.error("âŒ ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆå¤±æ•—")
            else:
                logger.error("âŒ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤ºæ›´æ–°å¤±æ•—: character_labelãŒNone")
                    
        except Exception as e:
            logger.error(f"âŒ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤ºæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def start_streaming(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹"""
        self.is_streaming = True
        if self.streaming_label:
            self.streaming_label.config(text="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­")
        logger.info("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹")
    
    def stop_streaming(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢"""
        self.is_streaming = False
        if self.streaming_label:
            self.streaming_label.config(text="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢")
        logger.info("âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢")
    
    def create_gui(self):
        """GUIä½œæˆ"""
        self.root = tk.Tk()
        self.root.title("å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ  - ã‚‚ã‚‚")
        self.root.geometry("1200x800")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦å´ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤º
        left_frame = ttk.Frame(main_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒè¡¨ç¤º
        self.character_label = ttk.Label(left_frame, text="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼èª­ã¿è¾¼ã¿ä¸­...")
        self.character_label.pack(fill=tk.BOTH, expand=True)
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒã‚’å³åº§ã«è¡¨ç¤º
        self.update_character_display()
        
        # å³å´ï¼šã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ«
        right_frame = ttk.Frame(main_frame)
        right_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=(10, 0))
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ttk.Label(right_frame, text="å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ ", font=("Arial", 14, "bold"))
        title_label.pack(pady=(0, 20))
        
        # ã‚³ãƒ¡ãƒ³ãƒˆå…¥åŠ›
        ttk.Label(right_frame, text="ã‚³ãƒ¡ãƒ³ãƒˆ:").pack(anchor=tk.W)
        self.comment_entry = ttk.Entry(right_frame, width=30)
        self.comment_entry.pack(fill=tk.X, pady=(0, 10))
        
        # é€ä¿¡ãƒœã‚¿ãƒ³
        send_button = ttk.Button(right_frame, text="é€ä¿¡", command=self.send_comment)
        send_button.pack(pady=(0, 20))
        
        # ã‚‚ã‚‚ã®è¿”ç­”
        ttk.Label(right_frame, text="ã‚‚ã‚‚ã®è¿”ç­”:").pack(anchor=tk.W)
        self.response_label = ttk.Label(right_frame, text="ã‚‚ã‚‚: ã“ã‚“ã«ã¡ã¯ï¼", wraplength=250)
        self.response_label.pack(anchor=tk.W, pady=(0, 10))
        
        # ç¾åœ¨ã®æ„Ÿæƒ…
        ttk.Label(right_frame, text="ç¾åœ¨ã®æ„Ÿæƒ…:").pack(anchor=tk.W)
        self.emotion_label = ttk.Label(right_frame, text="neutral", font=("Arial", 12, "bold"))
        self.emotion_label.pack(anchor=tk.W, pady=(0, 20))
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
        ttk.Label(right_frame, text="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°:").pack(anchor=tk.W)
        self.streaming_label = ttk.Label(right_frame, text="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢")
        self.streaming_label.pack(anchor=tk.W, pady=(0, 10))
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒœã‚¿ãƒ³
        streaming_button = ttk.Button(right_frame, text="ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹/åœæ­¢", command=self.toggle_streaming)
        streaming_button.pack(pady=(0, 20))
        
        # çµ‚äº†ãƒœã‚¿ãƒ³
        exit_button = ttk.Button(right_frame, text="çµ‚äº†", command=self.root.quit)
        exit_button.pack(side=tk.BOTTOM)
        
        # åˆæœŸåŒ–
        self.update_character_display()
        
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ›´æ–°ãƒ«ãƒ¼ãƒ—
        self.animation_loop()
    
    def send_comment(self):
        """ã‚³ãƒ¡ãƒ³ãƒˆé€ä¿¡"""
        comment = self.comment_entry.get().strip()
        if comment:
            logger.info(f"ã‚³ãƒ¡ãƒ³ãƒˆé€ä¿¡: {comment}")
            self.comment_entry.delete(0, tk.END)
            
            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†
            threading.Thread(target=self.process_comment, args=(comment,), daemon=True).start()
    
    def toggle_streaming(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ‡ã‚Šæ›¿ãˆ"""
        if self.is_streaming:
            self.stop_streaming()
        else:
            self.start_streaming()
    
    def animation_loop(self):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ—"""
        try:
            if self.animation_running:
                self.update_character_display()
                self.root.update_idletasks()  # GUIå¿œç­”æ€§ç¢ºä¿
        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 60fpsã§æ›´æ–°
        if self.root and self.root.winfo_exists():
            self.root.after(16, self.animation_loop)
    
    def start_animation(self):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹"""
        self.animation_running = True
        logger.info("âœ… ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
    
    def stop_animation(self):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åœæ­¢"""
        self.animation_running = False
        logger.info("âœ… ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åœæ­¢")
    
    def test_complete_system(self) -> bool:
        """å®Œå…¨ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        
        try:
            # GUIä½œæˆ
            self.create_gui()
            self.start_animation()
            
            # GUIè¡¨ç¤ºã¨å¿œç­”æ€§ç¢ºä¿
            self.root.update()
            self.root.update_idletasks()
            logger.info("âœ… GUIè¡¨ç¤ºå®Œäº†")
            
            # ãƒ†ã‚¹ãƒˆã‚³ãƒ¡ãƒ³ãƒˆå‡¦ç†
            test_comments = [
                "ã“ã‚“ã«ã¡ã¯ï¼",
                "ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­",
                "ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™",
                "ã¡ã‚‡ã£ã¨æ‚²ã—ã„ã§ã™"
            ]
            
            for comment in test_comments:
                logger.info(f"ãƒ†ã‚¹ãƒˆã‚³ãƒ¡ãƒ³ãƒˆ: {comment}")
                self.process_comment(comment)
                
                # å‡¦ç†å®Œäº†ã‚’å¾…ã¤ï¼ˆGUIå¿œç­”æ€§ã‚’ä¿ã¤ï¼‰
                while self.is_processing:
                    self.root.update()
                    self.root.update_idletasks()
                    time.sleep(0.1)
                
                # éŸ³å£°å†ç”Ÿå®Œäº†ã‚’å¾…ã¤ï¼ˆGUIå¿œç­”æ€§ã‚’ä¿ã¤ï¼‰
                while self.is_playing:
                    self.root.update()
                    self.root.update_idletasks()
                    time.sleep(0.1)
                
                # 1ç§’å¾…æ©Ÿï¼ˆGUIå¿œç­”æ€§ã‚’ä¿ã¤ï¼‰
                for _ in range(10):
                    self.root.update()
                    self.root.update_idletasks()
                    time.sleep(0.1)
            
            self.stop_animation()
            
            # GUIã‚’é–‰ã˜ã‚‹
            if self.root:
                self.root.quit()
                self.root.destroy()
            
            logger.info("âœ… å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def run(self):
        """ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œ"""
        try:
            logger.info("å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
            self.create_gui()
            self.start_animation()
            self.root.mainloop()
        except Exception as e:
            logger.error(f"âŒ ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self.stop_animation()
            logger.info("å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ çµ‚äº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ - Phase 3å®Œäº†ã¾ã§è‡ªå‹•å®Ÿè¡Œ"""
    try:
        logger.info("=== Phase 2B-3: å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ ===")
        
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        system = CompleteAIVTuberSystem()
        
        # Phase 2B: çµ±åˆã¨æœ€é©åŒ–
        logger.info("=== Phase 2B: çµ±åˆã¨æœ€é©åŒ–é–‹å§‹ ===")
        system.enable_realtime_video_generation(True)
        system.enable_lipsync(True)
        system.check_comfyui_connection()
        logger.info("âœ… Phase 2B: çµ±åˆã¨æœ€é©åŒ–å®Œäº†")
        
        # Phase 2C: ãƒ†ã‚¹ãƒˆã¨èª¿æ•´
        logger.info("=== Phase 2C: ãƒ†ã‚¹ãƒˆã¨èª¿æ•´é–‹å§‹ ===")
        test_result = system.run_integration_test()
        if test_result:
            system.optimize_system_performance()
            logger.info("âœ… Phase 2C: ãƒ†ã‚¹ãƒˆã¨èª¿æ•´å®Œäº†")
        else:
            logger.error("âŒ Phase 2C: ãƒ†ã‚¹ãƒˆã¨èª¿æ•´å¤±æ•—")
            return False
        
        # Phase 3: é…ä¿¡çµ±åˆã¨æœ€é©åŒ–
        logger.info("=== Phase 3: é…ä¿¡çµ±åˆã¨æœ€é©åŒ–é–‹å§‹ ===")
        system.setup_streaming_infrastructure()
        
        # é…ä¿¡ãƒ†ã‚¹ãƒˆï¼ˆçŸ­æ™‚é–“ï¼‰
        logger.info("é…ä¿¡ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆ30ç§’ï¼‰")
        if system.start_live_streaming():
            time.sleep(30)  # 30ç§’é–“é…ä¿¡
            system.stop_live_streaming()
            logger.info("âœ… é…ä¿¡ãƒ†ã‚¹ãƒˆå®Œäº†")
        else:
            logger.error("âŒ é…ä¿¡ãƒ†ã‚¹ãƒˆå¤±æ•—")
        
        # é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆï¼ˆ1æ™‚é–“ï¼‰
        logger.info("é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆ1æ™‚é–“ï¼‰")
        if system.run_continuous_streaming_test(duration_hours=1):
            logger.info("âœ… é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆå®Œäº†")
        else:
            logger.error("âŒ é€£ç¶šé…ä¿¡ãƒ†ã‚¹ãƒˆå¤±æ•—")
        
        logger.info("ğŸ‰ Phase 3: é…ä¿¡çµ±åˆã¨æœ€é©åŒ–å®Œäº†ï¼")
        logger.info("ğŸ‰ å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ  - å…¨Phaseå®Œäº†ï¼")
        
        # æœ€çµ‚ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        success = system.test_complete_system()
        
        if success:
            logger.info("ğŸ‰ å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ å®Œäº†ï¼")
            return True
        else:
            logger.error("âŒ å®Œå…¨çµ±åˆAI VTuberã‚·ã‚¹ãƒ†ãƒ å¤±æ•—")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
